{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final exam: Text Data Science\n",
    "\n",
    "In one of our labs, we saw how embeddings inherit subtle types 'gender bias' from the data they are trained on. In this exam we will do some further exploration of how embeddings\n",
    "represent gender. Specifically, we will use gender pronouns to split lists of similar words. We do this without assuming or implying that gender is a binary distinction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, load in the usual modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "import numpy as np\n",
    "import re\n",
    "import gensim\n",
    "\n",
    "import os\n",
    "# this turns off some pesky warnings\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"3\"\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=Warning)\n",
    "\n",
    "# direct plots to appear within the cell, and set their style\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plots\n",
    "plots.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the [gensim package](https://radimrehurek.com/gensim/index.html), as in our earlier labs. The following bit of code reads in 300-dimensional embedding vectors, trained using the [GloVe](https://nlp.stanford.edu/projects/glove/) algorithm on a collection of Wikipedia data. Specifically, it uses 6 billion tokens of Wikipedia, with a 400,000 word vocabulary. You can find other precompiled embeddings [here](https://www.diycode.cc/projects/RaRe-Technologies/gensim-data); you might be interested in swapping one or two of the in and seeing if the results change.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.downloader as gdl\n",
    "from gensim.models import KeyedVectors\n",
    "glove = gdl.load(\"glove-wiki-gigaword-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vocab = set([w for w in glove.vocab])\n",
    "print(\"The vocabulary size is %d\" % len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall the gender bias in analogies\n",
    "\n",
    "Recall that we uncovered several analogies that suggested 'societal bias' encoded in the analogies. This has been the topic of several academic studies. The nice example found in class (by Liana) is the following.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result1 = glove.most_similar(positive=['smart', 'boy'], negative=['girl'])\n",
    "result2 = glove.most_similar(positive=['smart', 'girl'], negative=['boy'])\n",
    "\n",
    "print('smart - girl + boy: ')\n",
    "print([x[0] for x in result1])\n",
    "\n",
    "print('smart - boy + girl: ')\n",
    "print([x[0] for x in result2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We'll now write a function that divides a set of words into two types: \"masculine\" and \"feminine.\" A word will be said to be more \"masculine\" than \"feminine\" if it is more similar to traditional male pronouns than it is to traditional female pronouns. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_words(words):\n",
    "    male = []\n",
    "    female = []\n",
    "    for w in words:\n",
    "        if glove.similarity(w, 'she') < glove.similarity(w, 'he'):\n",
    "            male.append(w)\n",
    "        else:\n",
    "            female.append(w)\n",
    "    return male, female\n",
    "    \n",
    "def split_similar_words(word):\n",
    "    words = [w[0] for w in glove.most_similar(word)]\n",
    "    return split_words(words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example. We'll split the list of words {'his', 'hers', 'mother', 'father', 'football', 'gymnastics', 'hockey', 'skating'} into those that are closer to 'he' and those that are closer to 'she'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "male, female = split_words(['his', 'hers', 'mother', 'father', 'football', 'gymnastics', 'hockey', 'skating'])\n",
    "print(male)\n",
    "print(female)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Explore some lists and comment\n",
    "\n",
    "Try out this function by evaluating it on different lists of words. Choose three lists, show the results, and comment in a Markdown cell on what you find. Why are the lists interesting? What do they imply about the embeddings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Splitting similar words\n",
    "\n",
    "Here's an example of the `split_similar_words` function. All this function does is to call `glove.most_similar` and then `split_words` on the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male, female = split_similar_words('family')\n",
    "print(male)\n",
    "print(female)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As above, try out the `split_similar_words` function by evaluating it on different words. Choose three words, show the results, and comment in a Markdown cell on what you find. Why are the lists interesting? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Modifying the function\n",
    "\n",
    "Now modify the function `split_words` to divide a list based on two sets of pronouns, the male list {'he', 'him', 'his'} and the female list {'she', 'her', 'hers'}. To do this, define the function `similarity` to be the *sum of the similarities of the word to each pronoun*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified to use two sets of gender pronouns, by \n",
    "male_pronouns = ['he', 'him', 'his']\n",
    "female_pronouns = ['she', 'her', 'hers']\n",
    "\n",
    "def similarity(w, word_list):\n",
    "    return ...\n",
    "\n",
    "def split_words2(words):\n",
    "    male = []\n",
    "    female = []\n",
    "    for w in words:\n",
    "        if similarity(w, female_pronouns) < similarity(w, male_pronouns):\n",
    "            male.append(w)\n",
    "        else:\n",
    "            female.append(w)\n",
    "    return male, female\n",
    "\n",
    "def split_similar_words2(word):\n",
    "    words = [w[0] for w in glove.most_similar(word)]\n",
    "    return split_words2(words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. How does the function change?\n",
    "\n",
    "Implement the function `similarity` above. Then, compare the functions `split_similar_words2` and `split_similar_words` on several examples. Does the new function work any better? Worse? Taken together, what do the examples you find say about the representation of gender embeddings? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Gender cycles\n",
    "\n",
    "To finish, we'll explore the interesting the fact that when we alternate between finding\n",
    "masculine and feminine words that are similar to a starting word, we quickly get a 2-cycle.\n",
    "\n",
    "This is best illustrated with an example. Starting with 'football,' we go through the most similar words and stop when we get to one that is \"more masculine than feminine.\"  Starting with that word, we go through its most similar words and stop when we get to one that is \"more feminine than masculine.\" We then repeat, alternating between masculine words and feminine words.\n",
    "\n",
    "Starting with 'football,' here is the sequence we find:\n",
    "\n",
    "football  -> soccer (m) -> volleyball (f) -> basketball (m) -> volleyball (f) -> basketball (m) -> volleyball (f) -> ...\n",
    "\n",
    "We can thus identify ('basketball', 'volleyball') as a \"male\"/\"female\" pair.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_masculine(word):\n",
    "    for x in glove.most_similar(word, topn=100):\n",
    "        if similarity(x[0], female_pronouns) < similarity(x[0],male_pronouns):\n",
    "            return x[0]\n",
    "    return None\n",
    "        \n",
    "def most_feminine(word):\n",
    "    for x in glove.most_similar(word, topn=100):\n",
    "        if similarity(x[0], female_pronouns) > similarity(x[0],male_pronouns):\n",
    "            return x[0]\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a function to find gender cycles\n",
    "\n",
    "To complete this exam, you now need to do two things. First, uncomment the following code block, and run it with the starting word 'football' and a few others. This depends on you defining the function `similarity` properly. Verify that you do indeed get the above cycle with 'football', 'volleyball' and 'basketball'. Try it out with different starting words.\n",
    "\n",
    "Then, use this code to define a function `def gender_pairs(word)` that takes the starting word `word` and returns a pair `(male_word, female_word)` that corresponds to a 2-cycle.\n",
    "Run the function on a few starting words that give interesting results. Comment on what you found in a Markdown cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word = 'football'\n",
    "#print('%s ' % word, end='')\n",
    "#for i in np.arange(10):\n",
    "#    prev = word\n",
    "#    next = most_masculine(prev)\n",
    "#    print(' -> %s (m)' % next, end=''),\n",
    "#    word = most_feminine(next)\n",
    "#    print(' -> %s (f)' % word, end=''),\n",
    "#    if word == prev:\n",
    "#        break\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_pairs(word):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit your exam\n",
    "\n",
    "When you are finished, submit your exam on Canvas in the usual way, printing to html/pdf and also uploading your notebook. Thank you!\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
